[OS]
save_dir = saves/defaults
save = True
word_file = %(save_dir)s/words.txt
tag_file = %(save_dir)s/tags.txt
rel_file = %(save_dir)s/rels.txt
embed_dir = data/glove/
embed_file = %(embed_dir)s/glove.6B.100d.txt
embed_aux_file = %(embed_dir)s/en.100d.aux.txt
data_dir = data/CTD
train_file = %(data_dir)s/ner_50000_vocab_train2
valid_file = %(data_dir)s/ner_50000_vocab_dev2
test_file = %(data_dir)s/ner_50000_vocab_test2

[Dataset]
cased = False
ensure_tree = True
root_label = root
add_to_pretrained = True
min_occur_count = 2
n_bkts = 40
n_valid_bkts = 10
lines_per_buffer = 0

[Layers]
n_recur = 3
recur_cell = LSTMCell
recur_bidir = True
forget_bias = 0

[Sizes]
embed_size = 100
recur_size = 400
attn_mlp_size = 500
class_mlp_size = 100
info_mlp_size = 500

[Functions]
recur_func = tanh
mlp_func = leaky_relu
info_func = leaky_relu

[Regularization]
word_l2_reg = 0

[Dropout]
word_keep_prob = .67
tag_keep_prob = .67
rel_keep_prob = 1
recur_keep_prob = .67
ff_keep_prob = .67
cell_include_prob = 1
hidden_include_prob = 1
mlp_keep_prob = .67
info_keep_prob = .67

[Learning rate]
learning_rate = 0.04
decay = .75
decay_steps = 5000
clip = 5

warmup_steps = 4000

[Radam]
mu = .9
nu = .9
gamma = 0
chi = 0
epsilon = 1e-12

[Training]
pretrain_iters = 1000
train_iters = 50000
train_batch_size = 5000
test_batch_size = 5000
validate_every = 500
print_every = 100
save_every = 500
per_process_gpu_memory_fraction = .95
cnn_dim = 1024
cnn_layers = 2
num_heads = 8
head_size = 64
relu_hidden_size = 512
eval_criterion = UAS
svd_tree = False
roots_penalty = 0.0
pairs_penalty = 0.0
svd_penalty = 0.0
mask_pairs = False
mask_roots = False
cnn_dim_2d = 128
cnn2d_layers = 0
num_blocks = 1

rel_loss_weight = 1.0
ner_loss_weight = 1.0
entity_loss_weight = 1.0

dist_model = transformer
lstm_residual = False
cnn_residual = True

multitask_penalties =
multitask_layers =

inject_manual_attn = False

use_bilinear = False

margin = 1.0
